{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b552daf-fbfc-4d11-815e-d3e84be36914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb67dcde-37b8-4b81-850a-ede0a4581f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP 1: Loading Data\n",
      "==================================================\n",
      "Dataset shape: (1985, 11)\n",
      "   Age  Salt_Intake  Stress_Score BP_History  Sleep_Duration   BMI Medication  \\\n",
      "0   69          8.0             9     Normal             6.4  25.8        NaN   \n",
      "1   32         11.7            10     Normal             5.4  23.4        NaN   \n",
      "2   78          9.5             3     Normal             7.1  18.7        NaN   \n",
      "\n",
      "  Family_History Exercise_Level Smoking_Status Has_Hypertension  \n",
      "0            Yes            Low     Non-Smoker              Yes  \n",
      "1             No            Low     Non-Smoker               No  \n",
      "2             No       Moderate     Non-Smoker               No  \n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"STEP 1: Loading Data\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "df = pd.read_csv('hypertension_dataset_cleaned.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f12ea7-30ca-4d07-b670-3a056ac560b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 2: Handling Missing Values\n",
      "==================================================\n",
      "Missing values after fix: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 2: Handling Missing Values\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "df['Medication'] = df['Medication'].fillna('None')\n",
    "print(f\"Missing values after fix: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2530ed-dac1-4d13-b4bd-cddc828ade9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 3: Encoding Categorical Columns\n",
      "==================================================\n",
      "  BP_History: ['Hypertension', 'Normal', 'Prehypertension']\n",
      "  Medication: ['ACE Inhibitor', 'Beta Blocker', 'Diuretic', 'None', 'Other']\n",
      "  Family_History: ['No', 'Yes']\n",
      "  Exercise_Level: ['High', 'Low', 'Moderate']\n",
      "  Smoking_Status: ['Non-Smoker', 'Smoker']\n",
      "  Target: ['No', 'Yes'] → [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 3: Encoding Categorical Columns\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "categorical_cols = ['BP_History', 'Medication', 'Family_History',\n",
    "                    'Exercise_Level', 'Smoking_Status']\n",
    "\n",
    "encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    encoders[col] = le\n",
    "    print(f\"  {col}: {list(le.classes_)}\")\n",
    "\n",
    "target_encoder = LabelEncoder()\n",
    "df['Has_Hypertension'] = target_encoder.fit_transform(df['Has_Hypertension'].astype(str))\n",
    "print(f\"  Target: {list(target_encoder.classes_)} → {list(range(len(target_encoder.classes_)))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca214bbd-d574-49fa-95b9-0aee19a00a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 4: Splitting Features and Target\n",
      "==================================================\n",
      "Features: ['Age', 'Salt_Intake', 'Stress_Score', 'BP_History', 'Sleep_Duration', 'BMI', 'Medication', 'Family_History', 'Exercise_Level', 'Smoking_Status']\n",
      "Target distribution:\n",
      "Has_Hypertension\n",
      "1    1032\n",
      "0     953\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 4: Splitting Features and Target\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X = df.drop('Has_Hypertension', axis=1)\n",
    "y = df['Has_Hypertension']\n",
    "\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "985ad08a-897e-46a0-9393-b21e41df638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 5: Train/Test Split (80/20)\n",
      "==================================================\n",
      "Training samples: 1588\n",
      "Testing samples:  397\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 5: Train/Test Split (80/20)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples:  {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf82402-4cfc-419f-9a7e-069b678dab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 6: Scaling Features\n",
      "==================================================\n",
      "Features scaled using StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 6: Scaling Features\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "print(\"Features scaled using StandardScaler.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9b218a1-d37e-434b-af00-77b807084de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 7: Training Random Forest Model\n",
      "==================================================\n",
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 7: Training Random Forest Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=28,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2919de3c-59c9-4f16-9cc9-b418fa235316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 8: Model Evaluation\n",
      "==================================================\n",
      "\n",
      "Train Accuracy: 94.02%\n",
      "Test Accuracy:  92.95%\n",
      "Difference:     1.07%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.95      0.93       191\n",
      "         Yes       0.95      0.91      0.93       206\n",
      "\n",
      "    accuracy                           0.93       397\n",
      "   macro avg       0.93      0.93      0.93       397\n",
      "weighted avg       0.93      0.93      0.93       397\n",
      "\n",
      "Confusion Matrix:\n",
      "[[182   9]\n",
      " [ 19 187]]\n",
      "\n",
      "Top Feature Importances:\n",
      "BP_History        0.453891\n",
      "Family_History    0.105736\n",
      "Stress_Score      0.104706\n",
      "Age               0.104182\n",
      "Smoking_Status    0.075481\n",
      "BMI               0.057588\n",
      "Sleep_Duration    0.053501\n",
      "Salt_Intake       0.040836\n",
      "Medication        0.003089\n",
      "Exercise_Level    0.000989\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 8: Model Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "train_acc = accuracy_score(y_train, model.predict(X_train_scaled))\n",
    "test_acc  = accuracy_score(y_test,  model.predict(X_test_scaled))\n",
    "\n",
    "print(f\"\\nTrain Accuracy: {train_acc * 100:.2f}%\")\n",
    "print(f\"Test Accuracy:  {test_acc  * 100:.2f}%\")\n",
    "print(f\"Difference:     {(train_acc - test_acc) * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, model.predict(X_test_scaled), target_names=target_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, model.predict(X_test_scaled)))\n",
    "\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "print(\"\\nTop Feature Importances:\")\n",
    "print(importances.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca40a920-fdee-4dc3-91dd-f11ea91d0f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 9: Saving PKL Files\n",
      "==================================================\n",
      "  ✓ model.pkl saved\n",
      "  ✓ scaler.pkl saved\n",
      "  ✓ encoders.pkl saved\n",
      "  ✓ target_encoder.pkl saved\n",
      "  ✓ feature_columns.pkl saved\n",
      "\n",
      "==================================================\n",
      "ALL DONE!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STEP 9: Saving PKL Files\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "output_dir = './'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "pickle.dump(model,           open(output_dir + 'model.pkl',           'wb'))\n",
    "pickle.dump(scaler,          open(output_dir + 'scaler.pkl',          'wb'))\n",
    "pickle.dump(encoders,        open(output_dir + 'encoders.pkl',        'wb'))\n",
    "pickle.dump(target_encoder,  open(output_dir + 'target_encoder.pkl',  'wb'))\n",
    "pickle.dump(list(X.columns), open(output_dir + 'feature_columns.pkl', 'wb'))\n",
    "\n",
    "print(\"  ✓ model.pkl saved\")\n",
    "print(\"  ✓ scaler.pkl saved\")\n",
    "print(\"  ✓ encoders.pkl saved\")\n",
    "print(\"  ✓ target_encoder.pkl saved\")\n",
    "print(\"  ✓ feature_columns.pkl saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ALL DONE!\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac10a1f0-d6b0-46be-b356-9f35a76ddc73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
